{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\switkowski\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\switkowski\\\\Documents\\\\Projects\\\\Topic-Model-MD-Legislation\\\\legislation_scraper\\\\data\\\\bill_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "purposes = data[~data.purpose.isnull()].purpose.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if len(token) > 3 and token not in gensim.parsing.preprocessing.STOPWORDS:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n",
    "\n",
    "\n",
    "processed_docs = [preprocess_text(purpose) for purpose in purposes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-f3b6ce3b015f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnlp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=100000, keep_tokens=None)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.050312126575677026),\n",
      " (1, 0.30109115574654272),\n",
      " (2, 0.035986118749956469),\n",
      " (3, 0.13864333075198568),\n",
      " (4, 0.018182591869913757),\n",
      " (5, 0.10223668642831536),\n",
      " (6, 0.043077897964631781),\n",
      " (7, 0.046115131161494946),\n",
      " (8, 0.096248429536687455),\n",
      " (9, 0.19438880688123947),\n",
      " (10, 0.074527371115247987),\n",
      " (11, 0.041688069553965333),\n",
      " (12, 0.21458489512776066),\n",
      " (13, 0.04534338367298435),\n",
      " (14, 0.056153247946907417),\n",
      " (15, 0.14717275634964649),\n",
      " (16, 0.055961579401005074),\n",
      " (17, 0.15997513276752651),\n",
      " (18, 0.40183804502346498),\n",
      " (19, 0.10574167522735853),\n",
      " (20, 0.15643085809995794),\n",
      " (21, 0.056347389703529788),\n",
      " (22, 0.21470313545821226),\n",
      " (23, 0.18171880089180056),\n",
      " (24, 0.18813385433411695),\n",
      " (25, 0.051538252627150186),\n",
      " (26, 0.20212275603797875),\n",
      " (27, 0.042678782324281531),\n",
      " (28, 0.023639888051606488),\n",
      " (29, 0.085625120610304847),\n",
      " (30, 0.080958598605320009),\n",
      " (31, 0.2198184899683594),\n",
      " (32, 0.12923369389389533),\n",
      " (33, 0.066201260015400248),\n",
      " (34, 0.19037427138017762),\n",
      " (35, 0.41457386811960462),\n",
      " (36, 0.087059136357816147),\n",
      " (37, 0.020376152198417645),\n",
      " (38, 0.079075421820085298),\n",
      " (39, 0.071039735633506337),\n",
      " (40, 0.21010893617863138)]\n"
     ]
    }
   ],
   "source": [
    "tfidf = gensim.models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(\n",
    "    corpus_tfidf, num_topics=25, id2word=dictionary, passes=2, workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0\n",
      "Words: 0.021*\"task\" + 0.019*\"forc\" + 0.012*\"workgroup\" + 0.009*\"studi\" + 0.008*\"recommend\" + 0.007*\"report\" + 0.007*\"counti\" + 0.006*\"assault\" + 0.005*\"governor\" + 0.005*\"find\"\n",
      "Topic: 1\n",
      "Words: 0.011*\"loan\" + 0.010*\"proceed\" + 0.007*\"licens\" + 0.007*\"vehicl\" + 0.005*\"director\" + 0.005*\"communiti\" + 0.005*\"test\" + 0.005*\"commiss\" + 0.005*\"child\" + 0.005*\"fund\"\n",
      "Topic: 2\n",
      "Words: 0.008*\"counti\" + 0.008*\"properti\" + 0.008*\"program\" + 0.008*\"fund\" + 0.008*\"exempt\" + 0.007*\"licens\" + 0.006*\"charl\" + 0.006*\"loan\" + 0.006*\"person\" + 0.006*\"proceed\"\n",
      "Topic: 3\n",
      "Words: 0.010*\"program\" + 0.009*\"depart\" + 0.006*\"counti\" + 0.006*\"health\" + 0.006*\"highway\" + 0.005*\"local\" + 0.005*\"revenu\" + 0.005*\"fund\" + 0.005*\"user\" + 0.005*\"sheriff\"\n",
      "Topic: 4\n",
      "Words: 0.023*\"licens\" + 0.013*\"class\" + 0.013*\"beer\" + 0.009*\"holder\" + 0.009*\"program\" + 0.008*\"patient\" + 0.007*\"wine\" + 0.007*\"alcohol\" + 0.006*\"beverag\" + 0.006*\"baltimor\"\n",
      "Topic: 5\n",
      "Words: 0.012*\"licens\" + 0.011*\"counti\" + 0.007*\"permit\" + 0.007*\"properti\" + 0.006*\"credit\" + 0.006*\"holder\" + 0.006*\"fund\" + 0.006*\"board\" + 0.005*\"compens\" + 0.005*\"health\"\n",
      "Topic: 6\n",
      "Words: 0.015*\"pharmaci\" + 0.015*\"hunt\" + 0.009*\"individu\" + 0.007*\"benefit\" + 0.007*\"deduct\" + 0.007*\"incom\" + 0.007*\"prohibit\" + 0.007*\"person\" + 0.007*\"loan\" + 0.007*\"item\"\n",
      "Topic: 7\n",
      "Words: 0.012*\"fund\" + 0.008*\"offic\" + 0.008*\"incom\" + 0.007*\"proceed\" + 0.007*\"loan\" + 0.007*\"school\" + 0.007*\"program\" + 0.006*\"counti\" + 0.006*\"depart\" + 0.006*\"medic\"\n",
      "Topic: 8\n",
      "Words: 0.009*\"loan\" + 0.008*\"program\" + 0.008*\"proceed\" + 0.007*\"leav\" + 0.007*\"employe\" + 0.006*\"maryland\" + 0.006*\"grant\" + 0.006*\"counti\" + 0.006*\"alter\" + 0.006*\"depart\"\n",
      "Topic: 9\n",
      "Words: 0.047*\"loan\" + 0.044*\"proceed\" + 0.016*\"encumbr\" + 0.016*\"deadlin\" + 0.016*\"creation\" + 0.016*\"debt\" + 0.016*\"disburs\" + 0.016*\"improv\" + 0.016*\"match\" + 0.016*\"bond\"\n",
      "Topic: 10\n",
      "Words: 0.007*\"counti\" + 0.006*\"proceed\" + 0.006*\"school\" + 0.006*\"medic\" + 0.005*\"loan\" + 0.005*\"assess\" + 0.005*\"incom\" + 0.005*\"sentenc\" + 0.005*\"affili\" + 0.005*\"fund\"\n",
      "Topic: 11\n",
      "Words: 0.018*\"loan\" + 0.017*\"proceed\" + 0.008*\"bond\" + 0.008*\"counti\" + 0.007*\"incom\" + 0.007*\"match\" + 0.007*\"fund\" + 0.007*\"issuanc\" + 0.006*\"develop\" + 0.006*\"board\"\n",
      "Topic: 12\n",
      "Words: 0.008*\"proceed\" + 0.007*\"credit\" + 0.007*\"loan\" + 0.007*\"baltimor\" + 0.006*\"individu\" + 0.006*\"inspector\" + 0.006*\"citi\" + 0.006*\"servic\" + 0.005*\"fund\" + 0.005*\"commiss\"\n",
      "Topic: 13\n",
      "Words: 0.015*\"retir\" + 0.010*\"veteran\" + 0.008*\"vehicl\" + 0.008*\"incom\" + 0.008*\"offic\" + 0.007*\"counti\" + 0.007*\"anim\" + 0.007*\"correct\" + 0.006*\"credit\" + 0.006*\"disabl\"\n",
      "Topic: 14\n",
      "Words: 0.012*\"licens\" + 0.011*\"alcohol\" + 0.010*\"counti\" + 0.010*\"beverag\" + 0.007*\"school\" + 0.007*\"fund\" + 0.007*\"loan\" + 0.007*\"georg\" + 0.007*\"princ\" + 0.006*\"proceed\"\n",
      "Topic: 15\n",
      "Words: 0.010*\"amend\" + 0.010*\"licens\" + 0.008*\"counti\" + 0.007*\"constitut\" + 0.006*\"court\" + 0.006*\"carrol\" + 0.006*\"collect\" + 0.006*\"applic\" + 0.005*\"agritour\" + 0.005*\"exempt\"\n",
      "Topic: 16\n",
      "Words: 0.019*\"loan\" + 0.017*\"proceed\" + 0.006*\"evid\" + 0.006*\"creation\" + 0.006*\"grant\" + 0.006*\"encumbr\" + 0.006*\"match\" + 0.006*\"deadlin\" + 0.006*\"debt\" + 0.006*\"disburs\"\n",
      "Topic: 17\n",
      "Words: 0.008*\"fund\" + 0.008*\"appropri\" + 0.007*\"loan\" + 0.007*\"amend\" + 0.006*\"proceed\" + 0.006*\"educ\" + 0.005*\"board\" + 0.005*\"year\" + 0.005*\"fiscal\" + 0.005*\"program\"\n",
      "Topic: 18\n",
      "Words: 0.047*\"loan\" + 0.044*\"proceed\" + 0.016*\"match\" + 0.015*\"encumbr\" + 0.015*\"creation\" + 0.015*\"deadlin\" + 0.015*\"debt\" + 0.015*\"improv\" + 0.015*\"disburs\" + 0.015*\"bond\"\n",
      "Topic: 19\n",
      "Words: 0.012*\"health\" + 0.009*\"servic\" + 0.008*\"depart\" + 0.007*\"insur\" + 0.007*\"commiss\" + 0.006*\"facil\" + 0.006*\"program\" + 0.006*\"maryland\" + 0.006*\"live\" + 0.006*\"member\"\n",
      "Topic: 20\n",
      "Words: 0.010*\"counti\" + 0.007*\"releas\" + 0.007*\"vehicl\" + 0.006*\"loan\" + 0.006*\"game\" + 0.006*\"proceed\" + 0.006*\"inmat\" + 0.006*\"program\" + 0.006*\"pretrial\" + 0.006*\"author\"\n",
      "Topic: 21\n",
      "Words: 0.011*\"credit\" + 0.009*\"properti\" + 0.009*\"depart\" + 0.007*\"homeown\" + 0.007*\"insur\" + 0.006*\"maryland\" + 0.006*\"program\" + 0.006*\"employe\" + 0.006*\"school\" + 0.006*\"applic\"\n",
      "Topic: 22\n",
      "Words: 0.009*\"student\" + 0.008*\"colleg\" + 0.007*\"communiti\" + 0.007*\"program\" + 0.006*\"depart\" + 0.006*\"counti\" + 0.006*\"incom\" + 0.006*\"proceed\" + 0.006*\"commiss\" + 0.006*\"loan\"\n",
      "Topic: 23\n",
      "Words: 0.015*\"loan\" + 0.014*\"proceed\" + 0.008*\"counti\" + 0.008*\"ann\" + 0.008*\"arundel\" + 0.008*\"licens\" + 0.007*\"board\" + 0.006*\"standard\" + 0.006*\"sale\" + 0.006*\"renew\"\n",
      "Topic: 24\n",
      "Words: 0.009*\"school\" + 0.009*\"handgun\" + 0.008*\"wear\" + 0.007*\"carri\" + 0.007*\"transport\" + 0.007*\"student\" + 0.007*\"permit\" + 0.007*\"public\" + 0.007*\"counti\" + 0.007*\"commiss\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: \" + str(idx))\n",
    "    print(\"Words: \" + topic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
